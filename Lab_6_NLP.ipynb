{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/akhilgandloju-206/NLP-ASSESSMENT-L91/blob/main/Lab_6_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Compare accuracy of Long sort term memory and Gated recurrent Unit models for text generation using data from tensorflow.keras.datasets."
      ],
      "metadata": {
        "id": "4bX_K6-gGQYr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NQCpB61y04m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wTQS8Twzsb4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mcbRdTlgzqcb",
        "outputId": "48c4f49f-8dcf-4b20-8972-552b75e77d3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "\u001b[1m17464789/17464789\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load IMDB dataset\n",
        "max_features = 10000  # Only consider the top 10k words\n",
        "max_len = 200  # Cut off texts after this number of words (for padding)\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dShVPT42zuR9"
      },
      "outputs": [],
      "source": [
        "# Pad sequences to ensure all inputs are of the same length\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0aQ932fz1yK"
      },
      "outputs": [],
      "source": [
        "# Build an LSTM model\n",
        "def build_lstm_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "    model.add(LSTM(128, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xNt5Wmhz4Vc"
      },
      "outputs": [],
      "source": [
        "# Build a GRU model\n",
        "def build_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "    model.add(GRU(128, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhuh9yorz-L_",
        "outputId": "631537a6-2be6-4241-e2ea-ca7080e015a4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training LSTM model...\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m174s\u001b[0m 547ms/step - accuracy: 0.6916 - loss: 0.5551 - val_accuracy: 0.8620 - val_loss: 0.3375\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 545ms/step - accuracy: 0.8921 - loss: 0.2706 - val_accuracy: 0.8016 - val_loss: 0.4075\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m166s\u001b[0m 532ms/step - accuracy: 0.9179 - loss: 0.2199 - val_accuracy: 0.8690 - val_loss: 0.3235\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m208s\u001b[0m 551ms/step - accuracy: 0.9509 - loss: 0.1394 - val_accuracy: 0.8544 - val_loss: 0.3666\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 526ms/step - accuracy: 0.9515 - loss: 0.1338 - val_accuracy: 0.8456 - val_loss: 0.3961\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the LSTM model\n",
        "lstm_model = build_lstm_model()\n",
        "print(\"Training LSTM model...\")\n",
        "lstm_history = lstm_model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5E7I9bkV0E0a",
        "outputId": "2628d470-476b-412e-d1ab-f5629e94e67b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GRU model...\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 631ms/step - accuracy: 0.6614 - loss: 0.5999 - val_accuracy: 0.8710 - val_loss: 0.3171\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m213s\u001b[0m 666ms/step - accuracy: 0.8929 - loss: 0.2683 - val_accuracy: 0.8474 - val_loss: 0.3586\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 630ms/step - accuracy: 0.9333 - loss: 0.1804 - val_accuracy: 0.8660 - val_loss: 0.3213\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 643ms/step - accuracy: 0.9614 - loss: 0.1130 - val_accuracy: 0.8472 - val_loss: 0.4790\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 620ms/step - accuracy: 0.9660 - loss: 0.1014 - val_accuracy: 0.8544 - val_loss: 0.4511\n"
          ]
        }
      ],
      "source": [
        "# Train and evaluate the GRU model\n",
        "gru_model = build_gru_model()\n",
        "print(\"Training GRU model...\")\n",
        "gru_history = gru_model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "XtjwOf6H0Mz0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31b58cd7-f536-4950-daf9-3f833795f5c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 129ms/step - accuracy: 0.8456 - loss: 0.4117\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 71ms/step - accuracy: 0.8544 - loss: 0.4701\n",
            "\n",
            "LSTM Test Accuracy: 0.8476\n",
            "GRU Test Accuracy: 0.8560\n"
          ]
        }
      ],
      "source": [
        "# Evaluate both models on the test set\n",
        "lstm_test_loss, lstm_test_acc = lstm_model.evaluate(x_test, y_test)\n",
        "gru_test_loss, gru_test_acc = gru_model.evaluate(x_test, y_test)\n",
        "\n",
        "# Print the comparison\n",
        "print(f\"\\nLSTM Test Accuracy: {lstm_test_acc:.4f}\")\n",
        "print(f\"GRU Test Accuracy: {gru_test_acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Load data fromkeras.datasets and perform following computational analysis:\n",
        "\n",
        "(a) Preprocessing of the Data\n",
        "\n",
        "(b) Divide data into training and testing data set\n",
        "\n",
        "(c) Build the Gated Recurrent Units (GRU) Model\n",
        "\n",
        "(d) Training the GRU Model\n",
        "\n",
        "(e) Text Generation Using the Trained Model\n",
        "\n",
        " (f)  Evaluate Model’s accuracy"
      ],
      "metadata": {
        "id": "fLZprbmFGsKD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "lkd7Roit0UMs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "605276f0-6f8b-4400-eb92-0fe8f0d67fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training GRU model...\n",
            "Epoch 1/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m189s\u001b[0m 595ms/step - accuracy: 0.6891 - loss: 0.5523 - val_accuracy: 0.8508 - val_loss: 0.3495\n",
            "Epoch 2/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 591ms/step - accuracy: 0.8996 - loss: 0.2565 - val_accuracy: 0.8712 - val_loss: 0.3122\n",
            "Epoch 3/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m185s\u001b[0m 592ms/step - accuracy: 0.9408 - loss: 0.1632 - val_accuracy: 0.8826 - val_loss: 0.3107\n",
            "Epoch 4/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 592ms/step - accuracy: 0.9619 - loss: 0.1083 - val_accuracy: 0.8756 - val_loss: 0.3749\n",
            "Epoch 5/5\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m224s\u001b[0m 662ms/step - accuracy: 0.9777 - loss: 0.0673 - val_accuracy: 0.8658 - val_loss: 0.4071\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 263ms/step\n",
            "Predicted sentiment for the input sequence: negative\n",
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 70ms/step - accuracy: 0.8654 - loss: 0.4432\n",
            "GRU Test Accuracy: 0.8655\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, GRU, Dense\n",
        "\n",
        "# 1. Load IMDB dataset\n",
        "max_features = 10000  # Only consider the top 10k words\n",
        "max_len = 200\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "\n",
        "\n",
        "# (a) Preprocessing of the Data\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n",
        "\n",
        "# (b) Divide data into training and testing data set\n",
        "# Already done in the previous code\n",
        "\n",
        "# (c) Build the GRU Model\n",
        "def build_gru_model():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(max_features, 128, input_length=max_len))\n",
        "    model.add(GRU(128, return_sequences=False))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "# (d) Training the GRU Model\n",
        "gru_model = build_gru_model()\n",
        "print(\"Training GRU model...\")\n",
        "gru_history = gru_model.fit(x_train, y_train, batch_size=64, epochs=5, validation_split=0.2)\n",
        "\n",
        "\n",
        "# (e) Text Generation Using the Trained Model\n",
        "seed_text = x_test[0]\n",
        "prediction = gru_model.predict(np.array([seed_text]))\n",
        "sentiment = \"positive\" if prediction > 0.5 else \"negative\"\n",
        "print(f\"Predicted sentiment for the input sequence: {sentiment}\")\n",
        "\n",
        "\n",
        "# (f) Evaluate Model’s Accuracy\n",
        "gru_test_loss, gru_test_acc = gru_model.evaluate(x_test, y_test)\n",
        "print(f\"GRU Test Accuracy: {gru_test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8r5SDO9YGNnt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LXMldQ0BGO1F"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO+MQ0KMZdF+ldxVCumuBVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}